"""
FlowerNet Outliner - æ–‡æ¡£å¤§çº²ç”Ÿæˆä¸å†…å®¹æç¤ºè¯ç®¡ç†
æ ¹æ®ç”¨æˆ·éœ€æ±‚ç”Ÿæˆæ–‡æ¡£ç»“æ„ï¼Œå¹¶ä¸ºæ¯ä¸ªæ®µè½ç”Ÿæˆä¸“ç”¨çš„ Content Prompt
"""

import os
import json
from typing import Optional, Dict, Any, List
from google import genai
from google.genai import types


class FlowerNetOutliner:
    """
    æ–‡æ¡£å¤§çº²ç”Ÿæˆå™¨
    - ç¬¬ä¸€é˜¶æ®µï¼šä½¿ç”¨ Document Structure Prompt ç”Ÿæˆå±‚çº§å¤§çº²
    - ç¬¬äºŒé˜¶æ®µï¼šä¸ºæ¯ä¸ª subsection ç”Ÿæˆ Content Prompt
    """
    
    def __init__(self, api_key: Optional[str] = None, model: str = "models/gemini-2.5-flash"):
        """
        åˆå§‹åŒ– Outliner
        
        Args:
            api_key: Google API Keyï¼ˆé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
            model: ä½¿ç”¨çš„ Gemini æ¨¡å‹
        """
        self.api_key = api_key or os.getenv('GOOGLE_API_KEY', '')
        if not self.api_key:
            raise ValueError("è¯·è®¾ç½® GOOGLE_API_KEY ç¯å¢ƒå˜é‡æˆ–ä¼ å…¥ api_key å‚æ•°")
        
        self.model = model
        self.client = genai.Client(api_key=self.api_key)
        
        print(f"âœ… Outliner åˆå§‹åŒ–æˆåŠŸ:")
        print(f"  - Model: {self.model}")
        print(f"  - Provider: Google Gemini")
    
    def generate_document_structure(
        self,
        user_background: str,
        user_requirements: str,
        max_sections: int = 5,
        max_subsections_per_section: int = 4
    ) -> Dict[str, Any]:
        """
        é˜¶æ®µ 1: ç”Ÿæˆæ–‡æ¡£ç»“æ„å¤§çº²
        
        Args:
            user_background: ç”¨æˆ·æä¾›çš„èƒŒæ™¯ä¿¡æ¯
            user_requirements: ç”¨æˆ·éœ€æ±‚æè¿°
            max_sections: æœ€å¤§ section æ•°é‡
            max_subsections_per_section: æ¯ä¸ª section æœ€å¤§ subsection æ•°é‡
            
        Returns:
            {
                "title": "æ–‡æ¡£æ ‡é¢˜",
                "sections": [
                    {
                        "id": "section_1",
                        "title": "Section æ ‡é¢˜",
                        "subsections": [
                            {"id": "subsection_1_1", "title": "å­æ ‡é¢˜", "description": "ç®€è¿°"},
                            ...
                        ]
                    },
                    ...
                ]
            }
        """
        # æ„å»º Document Structure Prompt
        structure_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£ç»“æ„è®¾è®¡ä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·æä¾›çš„èƒŒæ™¯å’Œéœ€æ±‚ï¼Œç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„æ–‡æ¡£å¤§çº²ã€‚

**ç”¨æˆ·èƒŒæ™¯**:
{user_background}

**ç”¨æˆ·éœ€æ±‚**:
{user_requirements}

**ä»»åŠ¡è¦æ±‚**:
1. ç”Ÿæˆä¸€ä¸ªæ¸…æ™°çš„æ–‡æ¡£æ ‡é¢˜
2. å°†æ–‡æ¡£åˆ†ä¸º {max_sections} ä¸ªå·¦å³çš„ä¸»è¦ç« èŠ‚ï¼ˆSectionï¼‰
3. æ¯ä¸ªç« èŠ‚åŒ…å« {max_subsections_per_section} ä¸ªå·¦å³çš„å­ç« èŠ‚ï¼ˆSubsectionï¼‰
4. æ¯ä¸ªå­ç« èŠ‚éœ€è¦æœ‰æ ‡é¢˜å’Œç®€çŸ­æè¿°ï¼ˆ1-2å¥è¯è¯´æ˜è¯¥æ®µåº”è¯¥å†™ä»€ä¹ˆï¼‰

**è¾“å‡ºæ ¼å¼**ï¼ˆä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼ï¼‰:
{{
  "title": "æ–‡æ¡£æ€»æ ‡é¢˜",
  "sections": [
    {{
      "id": "section_1",
      "title": "ç¬¬ä¸€ç« æ ‡é¢˜",
      "subsections": [
        {{
          "id": "subsection_1_1",
          "title": "ç¬¬ä¸€èŠ‚æ ‡é¢˜",
          "description": "è¯¥èŠ‚åº”è¯¥ä»‹ç»...ï¼ˆ1-2å¥è¯ï¼‰"
        }},
        {{
          "id": "subsection_1_2",
          "title": "ç¬¬äºŒèŠ‚æ ‡é¢˜",
          "description": "è¯¥èŠ‚åº”è¯¥è®¨è®º...ï¼ˆ1-2å¥è¯ï¼‰"
        }}
      ]
    }},
    {{
      "id": "section_2",
      "title": "ç¬¬äºŒç« æ ‡é¢˜",
      "subsections": [...]
    }}
  ]
}}

è¯·ç›´æ¥è¾“å‡º JSONï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–è¯´æ˜æˆ–ä»£ç å—æ ‡è®°ã€‚
"""
        
        try:
            # è°ƒç”¨ LLM ç”Ÿæˆå¤§çº²
            response = self.client.models.generate_content(
                model=self.model,
                contents=structure_prompt,
                config=types.GenerateContentConfig(
                    temperature=0.7,
                    max_output_tokens=4000
                )
            )
            
            # è§£æ JSON
            structure_text = response.text.strip()
            
            # ç§»é™¤å¯èƒ½çš„ä»£ç å—æ ‡è®°
            if structure_text.startswith("```json"):
                structure_text = structure_text[7:]
            if structure_text.startswith("```"):
                structure_text = structure_text[3:]
            if structure_text.endswith("```"):
                structure_text = structure_text[:-3]
            
            structure = json.loads(structure_text.strip())
            
            print(f"âœ… æ–‡æ¡£å¤§çº²ç”ŸæˆæˆåŠŸ:")
            print(f"  - æ ‡é¢˜: {structure.get('title', 'N/A')}")
            print(f"  - Sections: {len(structure.get('sections', []))}")
            
            return {
                "success": True,
                "structure": structure,
                "metadata": {
                    "model": self.model,
                    "prompt_tokens": response.usage_metadata.prompt_token_count if hasattr(response, 'usage_metadata') else 0,
                    "output_tokens": response.usage_metadata.candidates_token_count if hasattr(response, 'usage_metadata') else 0,
                }
            }
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON è§£æå¤±è´¥: {e}")
            print(f"åŸå§‹è¾“å‡º: {response.text[:500]}")
            return {
                "success": False,
                "error": f"JSON è§£æå¤±è´¥: {str(e)}",
                "raw_output": response.text
            }
        except Exception as e:
            print(f"âŒ å¤§çº²ç”Ÿæˆå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def generate_content_prompts(
        self,
        structure: Dict[str, Any],
        user_background: str,
        user_requirements: str
    ) -> List[Dict[str, Any]]:
        """
        é˜¶æ®µ 2: ä¸ºæ¯ä¸ª subsection ç”Ÿæˆ Content Prompt
        
        Args:
            structure: é˜¶æ®µ 1 ç”Ÿæˆçš„æ–‡æ¡£ç»“æ„
            user_background: ç”¨æˆ·èƒŒæ™¯
            user_requirements: ç”¨æˆ·éœ€æ±‚
            
        Returns:
            [
                {
                    "section_id": "section_1",
                    "subsection_id": "subsection_1_1",
                    "section_title": "ç« èŠ‚æ ‡é¢˜",
                    "subsection_title": "å­ç« èŠ‚æ ‡é¢˜",
                    "content_prompt": "ç”Ÿæˆè¯¥æ®µçš„è¯¦ç»†æç¤ºè¯",
                    "order": 1  # ç”Ÿæˆé¡ºåº
                },
                ...
            ]
        """
        content_prompts = []
        order = 1
        
        for section in structure.get("sections", []):
            section_id = section.get("id", "")
            section_title = section.get("title", "")
            
            for subsection in section.get("subsections", []):
                subsection_id = subsection.get("id", "")
                subsection_title = subsection.get("title", "")
                subsection_desc = subsection.get("description", "")
                
                # ä¸ºè¯¥ subsection ç”Ÿæˆ Content Prompt
                content_prompt = self._build_content_prompt(
                    document_title=structure.get("title", ""),
                    section_title=section_title,
                    subsection_title=subsection_title,
                    subsection_description=subsection_desc,
                    user_background=user_background,
                    user_requirements=user_requirements
                )
                
                content_prompts.append({
                    "section_id": section_id,
                    "subsection_id": subsection_id,
                    "section_title": section_title,
                    "subsection_title": subsection_title,
                    "subsection_description": subsection_desc,
                    "content_prompt": content_prompt,
                    "order": order
                })
                
                order += 1
        
        print(f"âœ… ç”Ÿæˆäº† {len(content_prompts)} ä¸ª Content Prompts")
        return content_prompts
    
    def _build_content_prompt(
        self,
        document_title: str,
        section_title: str,
        subsection_title: str,
        subsection_description: str,
        user_background: str,
        user_requirements: str
    ) -> str:
        """
        æ„å»ºå•ä¸ª subsection çš„ Content Prompt
        """
        prompt = f"""
ä½ æ­£åœ¨æ’°å†™ä¸€ç¯‡å…³äº"{document_title}"çš„æ–‡æ¡£ã€‚

**æ•´ä½“èƒŒæ™¯**:
{user_background}

**æ•´ä½“éœ€æ±‚**:
{user_requirements}

**å½“å‰ç« èŠ‚**: {section_title}
**å½“å‰å°èŠ‚**: {subsection_title}

**è¯¥å°èŠ‚è¦æ±‚**:
{subsection_description}

**å†™ä½œè¦æ±‚**:
1. ç´§æ‰£"{subsection_title}"è¿™ä¸ªä¸»é¢˜ï¼Œç¡®ä¿å†…å®¹ç›¸å…³æ€§
2. è¯¦ç»†å±•å¼€ï¼Œå­—æ•°æ§åˆ¶åœ¨ 500-800 å­—
3. ä½¿ç”¨æ¸…æ™°çš„é€»è¾‘ç»“æ„ï¼Œå¯ä»¥åŒ…å«å°æ ‡é¢˜
4. è¯­è¨€ä¸“ä¸šã€å‡†ç¡®ï¼Œé¿å…ç©ºæ´å†…å®¹
5. å¦‚æœæ¶‰åŠæŠ€æœ¯æ¦‚å¿µï¼Œéœ€è¦æä¾›å…·ä½“ä¾‹å­æˆ–è§£é‡Š
6. æ³¨æ„ä¸å‰é¢å·²ç”Ÿæˆå†…å®¹çš„è¡”æ¥ï¼Œé¿å…é‡å¤

è¯·ç›´æ¥è¾“å‡ºè¯¥å°èŠ‚çš„æ­£æ–‡å†…å®¹ï¼Œä¸è¦æ·»åŠ "è¯¥å°èŠ‚å†…å®¹å¦‚ä¸‹"ç­‰å¼•å¯¼è¯­ã€‚
"""
        return prompt.strip()
    
    def generate_full_outline(
        self,
        user_background: str,
        user_requirements: str,
        max_sections: int = 5,
        max_subsections_per_section: int = 4
    ) -> Dict[str, Any]:
        """
        å®Œæ•´æµç¨‹: ç”Ÿæˆæ–‡æ¡£ç»“æ„ + ä¸ºæ¯æ®µç”Ÿæˆ Content Prompt
        
        Returns:
            {
                "success": True,
                "document_title": "...",
                "structure": {...},
                "content_prompts": [...],
                "metadata": {...}
            }
        """
        # é˜¶æ®µ 1: ç”Ÿæˆå¤§çº²
        structure_result = self.generate_document_structure(
            user_background=user_background,
            user_requirements=user_requirements,
            max_sections=max_sections,
            max_subsections_per_section=max_subsections_per_section
        )
        
        if not structure_result.get("success"):
            return structure_result
        
        structure = structure_result["structure"]
        
        # é˜¶æ®µ 2: ç”Ÿæˆæ‰€æœ‰ Content Prompts
        content_prompts = self.generate_content_prompts(
            structure=structure,
            user_background=user_background,
            user_requirements=user_requirements
        )
        
        return {
            "success": True,
            "document_title": structure.get("title", ""),
            "structure": structure,
            "content_prompts": content_prompts,
            "total_subsections": len(content_prompts),
            "metadata": structure_result.get("metadata", {})
        }


# ============ æµ‹è¯•ä»£ç  ============

if __name__ == "__main__":
    # æµ‹è¯•ç”¨ä¾‹
    outliner = FlowerNetOutliner()
    
    result = outliner.generate_full_outline(
        user_background="æˆ‘æ˜¯ä¸€åè®¡ç®—æœºç§‘å­¦å­¦ç”Ÿï¼Œéœ€è¦æ’°å†™å…³äºäººå·¥æ™ºèƒ½çš„å­¦æœ¯è®ºæ–‡ã€‚",
        user_requirements="éœ€è¦ä¸€ç¯‡å…¨é¢ä»‹ç»äººå·¥æ™ºèƒ½çš„æ–‡ç« ï¼ŒåŒ…æ‹¬å†å²ã€æ ¸å¿ƒæŠ€æœ¯ã€åº”ç”¨åœºæ™¯å’Œæœªæ¥å±•æœ›ã€‚è¦æ±‚å†…å®¹ä¸“ä¸šã€é€»è¾‘æ¸…æ™°ã€‚",
        max_sections=4,
        max_subsections_per_section=3
    )
    
    if result["success"]:
        print(f"\nğŸ“„ æ–‡æ¡£æ ‡é¢˜: {result['document_title']}")
        print(f"ğŸ“Š æ€»å…± {result['total_subsections']} ä¸ªæ®µè½éœ€è¦ç”Ÿæˆ\n")
        
        # æ˜¾ç¤ºå‰ 3 ä¸ª Content Prompt
        for prompt_info in result["content_prompts"][:3]:
            print(f"--- {prompt_info['section_title']} > {prompt_info['subsection_title']} ---")
            print(f"Prompt é•¿åº¦: {len(prompt_info['content_prompt'])} å­—ç¬¦\n")
    else:
        print(f"âŒ å¤±è´¥: {result.get('error')}")
