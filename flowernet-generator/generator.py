"""
FlowerNet Generator - LLMé©±åŠ¨çš„å†…å®¹ç”Ÿæˆæ¨¡å—
æ ¹æ®promptä½¿ç”¨LLMç”Ÿæˆdraftå†…å®¹
æ”¯æŒå¤šç§ LLM æä¾›å•†: Anthropic Claude, Google Gemini
"""

import os
import requests
import json
from typing import Optional, Dict, Any, List

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

try:
    from google import genai
    from google.genai import types
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False


class FlowerNetGenerator:
    """
    å†…å®¹ç”Ÿæˆå™¨ï¼šæ”¯æŒå¤šç§ LLM æä¾›å•†
    - Anthropic Claude (éœ€è¦ ANTHROPIC_API_KEY)
    - Google Gemini (éœ€è¦ GOOGLE_API_KEYï¼Œå®Œå…¨å…è´¹)
    """
    
    def __init__(self, api_key: Optional[str] = None, model: str = "models/gemini-2.5-flash", provider: str = "gemini"):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨
        
        Args:
            api_key: API keyï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
                - Claude: "claude-3-5-sonnet-20241022"
                - Gemini: "models/gemini-2.5-flash" (å…è´¹, æœ€æ–°), "models/gemini-2.5-pro" (å…è´¹ä½†æœ‰é™åˆ¶)
            provider: LLM æä¾›å•† ("claude" æˆ– "gemini")
        """
        self.provider = provider.lower()
        self.model = model
        self.public_url = os.getenv('GENERATOR_PUBLIC_URL', 'http://localhost:8002')
        
        # æ ¹æ®æä¾›å•†åˆå§‹åŒ–
        if self.provider == "gemini":
            if not GEMINI_AVAILABLE:
                raise ImportError("éœ€è¦å®‰è£… google-genai: pip install google-genai")
            
            self.api_key = api_key or os.getenv('GOOGLE_API_KEY', '')
            if not self.api_key:
                raise ValueError("è¯·è®¾ç½® GOOGLE_API_KEY ç¯å¢ƒå˜é‡æˆ–ä¼ å…¥ api_key å‚æ•°")
            
            self.client = genai.Client(api_key=self.api_key)
            
            print(f"âœ… Generator åˆå§‹åŒ– (Google Gemini - å…è´¹):")
            print(f"  - Model: {self.model}")
            print(f"  - Provider: Google Gemini")
            print(f"  - Public URL: {self.public_url}")
            
        elif self.provider == "claude":
            if not ANTHROPIC_AVAILABLE:
                raise ImportError("éœ€è¦å®‰è£… anthropic: pip install anthropic")
            
            self.api_key = api_key or os.getenv('ANTHROPIC_API_KEY', '')
            if not self.api_key:
                raise ValueError("è¯·è®¾ç½® ANTHROPIC_API_KEY ç¯å¢ƒå˜é‡æˆ–ä¼ å…¥ api_key å‚æ•°")
            
            self.client = anthropic.Anthropic(api_key=self.api_key)
            
            print(f"âœ… Generator åˆå§‹åŒ– (Anthropic Claude):")
            print(f"  - Model: {self.model}")
            print(f"  - Provider: Anthropic Claude")
            print(f"  - Public URL: {self.public_url}")
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æä¾›å•†: {provider}ã€‚è¯·ä½¿ç”¨ 'claude' æˆ– 'gemini'")

    def generate_draft(self, prompt: str, max_tokens: int = 2000) -> Dict[str, Any]:
        """
        ä½¿ç”¨ LLM æ ¹æ® prompt ç”Ÿæˆ draft
        
        Args:
            prompt: ç”ŸæˆæŒ‡ä»¤
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
            
        Returns:
            åŒ…å«ç”Ÿæˆæ–‡æœ¬å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        try:
            if self.provider == "gemini":
                return self._generate_with_gemini(prompt, max_tokens)
            elif self.provider == "claude":
                return self._generate_with_claude(prompt, max_tokens)
            else:
                raise ValueError(f"æœªçŸ¥çš„æä¾›å•†: {self.provider}")
        except Exception as e:
            return {
                "success": False,
                "error": f"Error: {str(e)}",
                "draft": ""
            }
    
    def _generate_with_gemini(self, prompt: str, max_tokens: int) -> Dict[str, Any]:
        """ä½¿ç”¨ Google Gemini ç”Ÿæˆå†…å®¹"""
        try:
            # Gemini çš„ max_output_tokens é™åˆ¶ä¼šå¯¼è‡´è¾“å‡ºè¿‡çŸ­
            # å¦‚æœ max_tokens < 4000ï¼Œä¸è®¾ç½®é™åˆ¶è®©æ¨¡å‹è‡ªç”±å‘æŒ¥
            # å¦‚æœ max_tokens >= 4000ï¼Œåˆ™è®¾ç½®é™åˆ¶
            config_params = {
                "temperature": 0.7,
            }
            
            if max_tokens >= 4000:
                config_params["max_output_tokens"] = max_tokens
            
            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt,
                config=types.GenerateContentConfig(**config_params)
            )
            
            draft_text = response.text
            
            return {
                "success": True,
                "draft": draft_text,
                "metadata": {
                    "model": self.model,
                    "provider": "gemini",
                    "prompt_tokens": response.usage_metadata.prompt_token_count if hasattr(response, 'usage_metadata') else 0,
                    "output_tokens": response.usage_metadata.candidates_token_count if hasattr(response, 'usage_metadata') else 0,
                    "finish_reason": str(response.candidates[0].finish_reason) if response.candidates else "UNKNOWN",
                }
            }
        except Exception as e:
            return {
                "success": False,
                "error": f"çŒ«å’ªæŠ¥é”™ğŸ± ï¼šGemini API Error: {str(e)}ï¼Œ é”™äº†å’ªï¼",
                "draft": ""
            }
    
    def _generate_with_claude(self, prompt: str, max_tokens: int) -> Dict[str, Any]:
        """ä½¿ç”¨ Anthropic Claude ç”Ÿæˆå†…å®¹"""
        try:
            message = self.client.messages.create(
                model=self.model,
                max_tokens=max_tokens,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )
            
            draft_text = message.content[0].text
            
            return {
                "success": True,
                "draft": draft_text,
                "metadata": {
                    "model": self.model,
                    "provider": "claude",
                    "input_tokens": message.usage.input_tokens,
                    "output_tokens": message.usage.output_tokens,
                    "stop_reason": message.stop_reason,
                }
            }
        except Exception as e:
            return {
                "success": False,
                "error": f"Claude API Error: {str(e)}",
                "draft": ""
            }

    def generate_with_context(
        self,
        prompt: str,
        outline: str,
        history: List[str],
        max_tokens: int = 2000
    ) -> Dict[str, Any]:
        """
        æ ¹æ®ä¸Šä¸‹æ–‡ç”Ÿæˆå†…å®¹ï¼ˆå¸¦å¤§çº²å’Œå†å²è®°å½•ï¼‰
        
        Args:
            prompt: ç”ŸæˆæŒ‡ä»¤
            outline: å½“å‰å¤§çº²/ä»»åŠ¡
            history: ä¹‹å‰ç”Ÿæˆçš„å†…å®¹åˆ—è¡¨
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
            
        Returns:
            åŒ…å«ç”Ÿæˆæ–‡æœ¬å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        context_str = "\n".join(history) if history else "No previous content yet."
        
        full_prompt = f"""
èƒŒæ™¯ä¿¡æ¯ï¼š
- å¤§çº²/ä»»åŠ¡: {outline}
- å†å²å†…å®¹: {context_str}

ç”ŸæˆæŒ‡ä»¤ï¼š
{prompt}

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ç”Ÿæˆå†…å®¹ã€‚
"""
        
        return self.generate_draft(full_prompt, max_tokens)


class FlowerNetOrchestrator:
    """
    FlowerNet æµç¨‹ç¼–æ’å™¨ï¼š
    ç®¡ç†æ•´ä¸ªå¾ªç¯æµç¨‹ï¼ˆGenerator -> Verifier -> Controller -> Generator ...ï¼‰
    """
    
    def __init__(
        self,
        generator_url: str = "http://localhost:8002",
        verifier_url: str = "http://localhost:8000",
        controller_url: str = "http://localhost:8001",
        max_iterations: int = 5
    ):
        """
        åˆå§‹åŒ–ç¼–æ’å™¨
        
        Args:
            generator_url: Generator æœåŠ¡çš„ URL
            verifier_url: Verifier æœåŠ¡çš„ URL
            controller_url: Controller æœåŠ¡çš„ URL
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        """
        self.generator_url = generator_url
        self.verifier_url = verifier_url
        self.controller_url = controller_url
        self.max_iterations = max_iterations
        self.session = requests.Session()
        
        print(f"ğŸŒ¸ FlowerNet ç¼–æ’å™¨åˆå§‹åŒ–:")
        print(f"  - Generator URL: {generator_url}")
        print(f"  - Verifier URL: {verifier_url}")
        print(f"  - Controller URL: {controller_url}")
        print(f"  - Max iterations: {max_iterations}")

    def generate_section(
        self,
        outline: str,
        initial_prompt: str,
        history: Optional[List[str]] = None,
        rel_threshold: float = 0.6,
        red_threshold: float = 0.7
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆä¸€ä¸ªæ®µè½ï¼Œå¹¶è¿›è¡ŒéªŒè¯-ä¿®æ”¹çš„å¾ªç¯
        
        æµç¨‹ï¼š
        1. Generator æ ¹æ® prompt ç”Ÿæˆ draft
        2. Verifier æ£€éªŒ draftï¼ˆç›¸å…³æ€§å’Œå†—ä½™åº¦ï¼‰
        3. å¦‚æœéªŒè¯ä¸é€šè¿‡ï¼ŒController ä¿®æ”¹ prompt
        4. å›åˆ°æ­¥éª¤1ï¼Œç›´åˆ°éªŒè¯é€šè¿‡æˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
        
        Args:
            outline: æ®µè½å¤§çº²
            initial_prompt: åˆå§‹ç”Ÿæˆæç¤º
            history: å†å²å†…å®¹åˆ—è¡¨
            rel_threshold: ç›¸å…³æ€§é˜ˆå€¼
            red_threshold: å†—ä½™åº¦é˜ˆå€¼
            
        Returns:
            åŒ…å«æœ€ç»ˆç”Ÿæˆå†…å®¹å’Œè¿­ä»£è¿‡ç¨‹çš„å­—å…¸
        """
        if history is None:
            history = []
        
        current_prompt = initial_prompt
        iterations = 0
        all_drafts = []
        
        print(f"\n{'='*60}")
        print(f"ğŸ“ å¼€å§‹ç”Ÿæˆæ®µè½: {outline}")
        print(f"{'='*60}")
        
        while iterations < self.max_iterations:
            iterations += 1
            print(f"\n--- è¿­ä»£ {iterations}/{self.max_iterations} ---")
            
            # 1ï¸âƒ£ è°ƒç”¨ Generator ç”Ÿæˆ draft
            print(f"ğŸ¯ [Generator] ç”Ÿæˆ draft...")
            gen_response = self._call_generator(current_prompt)
            
            if not gen_response.get("success"):
                print(f"âŒ Generator å‡ºé”™: {gen_response.get('error')}")
                return {
                    "success": False,
                    "error": f"Generator é”™è¯¯: {gen_response.get('error')}",
                    "iterations": iterations
                }
            
            draft = gen_response.get("draft", "")
            all_drafts.append(draft)
            print(f"âœ… ç”Ÿæˆäº† {len(draft)} å­—ç¬¦çš„å†…å®¹")
            
            # 2ï¸âƒ£ è°ƒç”¨ Verifier éªŒè¯ draft
            print(f"ğŸ” [Verifier] éªŒè¯å†…å®¹...")
            verify_response = self._call_verifier(
                draft=draft,
                outline=outline,
                history=history,
                rel_threshold=rel_threshold,
                red_threshold=red_threshold
            )
            
            if not verify_response.get("success"):
                print(f"âŒ Verifier å‡ºé”™: {verify_response.get('error')}")
                return {
                    "success": False,
                    "error": f"Verifier é”™è¯¯: {verify_response.get('error')}",
                    "iterations": iterations
                }
            
            is_passed = verify_response.get("is_passed", False)
            rel_score = verify_response.get("relevancy_index", 0)
            red_score = verify_response.get("redundancy_index", 0)
            feedback = verify_response.get("feedback", "")
            
            print(f"ğŸ“Š ç›¸å…³æ€§: {rel_score:.4f} (é˜ˆå€¼: {rel_threshold})")
            print(f"ğŸ“Š å†—ä½™åº¦: {red_score:.4f} (é˜ˆå€¼: {red_threshold})")
            print(f"ğŸ’¬ åé¦ˆ: {feedback}")
            
            # 3ï¸âƒ£ å¦‚æœéªŒè¯é€šè¿‡ï¼Œè¿”å›ç»“æœ
            if is_passed:
                print(f"\nâœ¨ å†…å®¹éªŒè¯é€šè¿‡ï¼")
                history.append(draft)
                return {
                    "success": True,
                    "draft": draft,
                    "iterations": iterations,
                    "verification": {
                        "relevancy_index": rel_score,
                        "redundancy_index": red_score,
                        "feedback": feedback
                    },
                    "all_drafts": all_drafts
                }
            
            # 4ï¸âƒ£ å¦‚æœéªŒè¯ä¸é€šè¿‡ï¼Œè°ƒç”¨ Controller ä¿®æ”¹ prompt
            print(f"ğŸ”§ [Controller] ä¿®æ”¹ prompt...")
            controller_response = self._call_controller(
                old_prompt=current_prompt,
                failed_draft=draft,
                feedback=verify_response,
                outline=outline,
                history=history
            )
            
            if not controller_response.get("success"):
                print(f"âŒ Controller å‡ºé”™: {controller_response.get('error')}")
                return {
                    "success": False,
                    "error": f"Controller é”™è¯¯: {controller_response.get('error')}",
                    "iterations": iterations
                }
            
            current_prompt = controller_response.get("prompt", "")
            print(f"âœ… Prompt å·²ä¿®æ”¹ï¼Œå‡†å¤‡ä¸‹ä¸€è½®ç”Ÿæˆ...")
        
        # å¦‚æœè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ä»æœªé€šè¿‡
        print(f"\nâš ï¸  è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° ({self.max_iterations})ï¼Œç”Ÿæˆè¿‡ç¨‹ç»“æŸ")
        
        # è¿”å›æœ€åç”Ÿæˆçš„ draft ä½œä¸ºç»“æœ
        if all_drafts:
            history.append(all_drafts[-1])
            return {
                "success": True,
                "draft": all_drafts[-1],
                "iterations": iterations,
                "warning": f"è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå¯èƒ½å†…å®¹ä¸å®Œå…¨ç¬¦åˆè¦æ±‚",
                "all_drafts": all_drafts
            }
        
        return {
            "success": False,
            "error": "æ— æ³•ç”Ÿæˆæ»¡è¶³è¦æ±‚çš„å†…å®¹",
            "iterations": iterations
        }

    def _call_generator(self, prompt: str) -> Dict[str, Any]:
        """è°ƒç”¨ Generator API"""
        try:
            response = self.session.post(
                f"{self.generator_url}/generate",
                json={"prompt": prompt},
                timeout=60
            )
            return response.json()
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    def _call_verifier(
        self,
        draft: str,
        outline: str,
        history: List[str],
        rel_threshold: float = 0.6,
        red_threshold: float = 0.7
    ) -> Dict[str, Any]:
        """è°ƒç”¨ Verifier API"""
        try:
            response = self.session.post(
                f"{self.verifier_url}/verify",
                json={
                    "draft": draft,
                    "outline": outline,
                    "history": history,
                    "rel_threshold": rel_threshold,
                    "red_threshold": red_threshold
                },
                timeout=60
            )
            data = response.json()
            return {
                "success": True,
                **data
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    def _call_controller(
        self,
        old_prompt: str,
        failed_draft: str,
        feedback: Dict[str, Any],
        outline: str,
        history: List[str]
    ) -> Dict[str, Any]:
        """è°ƒç”¨ Controller API"""
        try:
            response = self.session.post(
                f"{self.controller_url}/refine_prompt",
                json={
                    "old_prompt": old_prompt,
                    "failed_draft": failed_draft,
                    "feedback": feedback,
                    "outline": outline,
                    "history": history
                },
                timeout=60
            )
            return response.json()
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    def generate_document(
        self,
        title: str,
        outline_list: List[str],
        system_prompt: str = "",
        rel_threshold: float = 0.6,
        red_threshold: float = 0.7
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆå®Œæ•´æ–‡æ¡£ï¼ˆå¤šä¸ªæ®µè½ï¼‰
        
        Args:
            title: æ–‡æ¡£æ ‡é¢˜
            outline_list: å¤§çº²åˆ—è¡¨
            system_prompt: ç³»ç»Ÿçº§æç¤ºï¼ˆå¯¹æ‰€æœ‰æ®µè½é€‚ç”¨ï¼‰
            rel_threshold: ç›¸å…³æ€§é˜ˆå€¼
            red_threshold: å†—ä½™åº¦é˜ˆå€¼
            
        Returns:
            åŒ…å«å®Œæ•´æ–‡æ¡£å’Œç”Ÿæˆè¿‡ç¨‹çš„å­—å…¸
        """
        print(f"\n{'#'*60}")
        print(f"ğŸ“„ å¼€å§‹ç”Ÿæˆæ–‡æ¡£: {title}")
        print(f"{'#'*60}")
        print(f"å¤§çº²: {outline_list}")
        
        document = {
            "title": title,
            "sections": [],
            "total_iterations": 0,
            "success_count": 0,
            "failed_sections": []
        }
        
        history = []
        
        for idx, outline in enumerate(outline_list, 1):
            print(f"\n[{idx}/{len(outline_list)}] ç”Ÿæˆæ®µè½...")
            
            # ä¸ºæ¯ä¸ªæ®µè½ç”Ÿæˆåˆå§‹ prompt
            initial_prompt = self._generate_initial_prompt(
                system_prompt=system_prompt,
                outline=outline,
                section_number=idx,
                total_sections=len(outline_list)
            )
            
            # è°ƒç”¨ç”Ÿæˆ-éªŒè¯å¾ªç¯
            result = self.generate_section(
                outline=outline,
                initial_prompt=initial_prompt,
                history=history,
                rel_threshold=rel_threshold,
                red_threshold=red_threshold
            )
            
            document["total_iterations"] += result.get("iterations", 0)
            
            if result.get("success"):
                document["sections"].append({
                    "outline": outline,
                    "content": result.get("draft", ""),
                    "iterations": result.get("iterations", 0),
                    "verification": result.get("verification", {})
                })
                document["success_count"] += 1
                history.append(result.get("draft", ""))
            else:
                document["failed_sections"].append({
                    "outline": outline,
                    "error": result.get("error", "Unknown error")
                })
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        print(f"\n{'#'*60}")
        print(f"ğŸ“Š æ–‡æ¡£ç”Ÿæˆå®Œæˆ")
        print(f"{'#'*60}")
        print(f"âœ… æˆåŠŸæ®µè½: {document['success_count']}/{len(outline_list)}")
        print(f"âŒ å¤±è´¥æ®µè½: {len(document['failed_sections'])}/{len(outline_list)}")
        print(f"æ€»è¿­ä»£æ¬¡æ•°: {document['total_iterations']}")
        
        return document

    def _generate_initial_prompt(
        self,
        system_prompt: str,
        outline: str,
        section_number: int = 1,
        total_sections: int = 1
    ) -> str:
        """ç”Ÿæˆåˆå§‹ prompt"""
        prompt = f"""
ä»»åŠ¡ï¼šç¼–å†™å†…å®¹æ®µè½

æ®µè½ç¼–å·: {section_number}/{total_sections}
æ®µè½ä¸»é¢˜: {outline}

"""
        if system_prompt:
            prompt += f"ç³»ç»ŸæŒ‡ç¤º: {system_prompt}\n\n"
        
        prompt += f"""
è¯·æ ¹æ®ä¸Šè¿°ä¸»é¢˜ç¼–å†™ä¸€æ®µç›¸å…³å†…å®¹ã€‚è¦æ±‚ï¼š
1. å†…å®¹åº”ä¸¥æ ¼å›´ç»•ä¸»é¢˜ã€Œ{outline}ã€å±•å¼€
2. æ®µè½åº”è¯¥é€»è¾‘æ¸…æ™°ã€è¡¨è¿°å‡†ç¡®
3. é¿å…ä¸ä¹‹å‰çš„å†…å®¹é‡å¤ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
4. é•¿åº¦é€‚ä¸­ï¼ˆ200-500 å­—ï¼‰
"""
        
        return prompt
