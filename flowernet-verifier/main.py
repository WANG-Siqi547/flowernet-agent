from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Optional
import uvicorn
import numpy as np
import jieba
import os
from rank_bm25 import BM25Okapi
from rouge_score import rouge_scorer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation

from history_store import HistoryManager


# ============ FlowerNetVerifier è½»é‡çº§ç‰ˆæœ¬ ============
class FlowerNetVerifier:
    def __init__(self):
        print("ğŸŒ¸ FlowerNet éªŒè¯å±‚å¯åŠ¨ï¼ˆè½»é‡çº§æ¨¡å¼ï¼‰")
        self.public_url = os.getenv('VERIFIER_PUBLIC_URL', 'http://localhost:8000')
        print(f"  - Verifier Public URL: {self.public_url}")
        self.scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)
        self.vectorizer = CountVectorizer(stop_words='english', max_features=1000)
        print("âœ… éªŒè¯å±‚å°±ç»ªï¼ˆä»…ä½¿ç”¨ä¼ ç»Ÿ NLPï¼‰")

    def _tokenize(self, text):
        """åˆ†è¯"""
        tokens = [t.strip().lower() for t in jieba.cut(text)]
        return [t for t in tokens if t]

    def calculate_relevancy(self, draft, outline):
        """è®¡ç®—è‰ç¨¿ä¸å¤§çº²çš„ç›¸å…³æ€§"""
        outline_tokens = [w for w in self._tokenize(outline) if len(w) > 1]
        draft_tokens = [w for w in self._tokenize(draft) if len(w) > 1]
        
        if outline_tokens:
            outline_keywords = set(outline_tokens)
            draft_keywords = set(draft_tokens)
            keyword_coverage = len(outline_keywords & draft_keywords) / len(outline_keywords)
        else:
            keyword_coverage = 0.0

        try:
            bm25 = BM25Okapi([outline_tokens, draft_tokens])
            bm25_score = bm25.get_scores(draft_tokens)[0] / (bm25.get_scores(draft_tokens).max() + 1e-9)
        except:
            bm25_score = 0.5

        length_score = min(len(draft) / max(len(outline), 1), 1.0)
        # æé«˜å…³é”®è¯è¦†ç›–ç‡æƒé‡ï¼Œé™ä½é•¿åº¦å½±å“
        relevancy_score = (keyword_coverage * 0.6) + (bm25_score * 0.3) + (length_score * 0.1)

        return {
            "score": float(round(relevancy_score, 4)),
            "details": {
                "keyword_coverage": float(keyword_coverage),
                "bm25_similarity": float(bm25_score),
                "length_score": float(length_score),
            },
        }

    def calculate_redundancy(self, draft, history_list):
        """è®¡ç®—å†—ä½™åº¦"""
        if not history_list:
            return {"score": 0.0, "details": "No history yet"}

        all_histories = " ".join(history_list)
        draft_tokens_list = [t for t in self._tokenize(draft) if len(t) > 1]
        history_tokens_list = [t for t in self._tokenize(all_histories) if len(t) > 1]
        draft_tokens_set = set(draft_tokens_list)
        history_tokens_set = set(history_tokens_list)

        if draft_tokens_set:
            token_overlap = len(draft_tokens_set & history_tokens_set) / len(draft_tokens_set)
        else:
            token_overlap = 0.0

        draft_bigrams = set(zip(draft_tokens_list, draft_tokens_list[1:]))
        history_bigrams = set(zip(history_tokens_list, history_tokens_list[1:]))
        
        if draft_bigrams:
            bigram_overlap = len(draft_bigrams & history_bigrams) / len(draft_bigrams)
        else:
            bigram_overlap = 0.0

        # æé«˜å•è¯é‡å æƒé‡ï¼Œæ›´ä¸¥æ ¼æ£€æµ‹å†—ä½™
        redundancy_score = (token_overlap * 0.7) + (bigram_overlap * 0.3)

        return {
            "score": float(round(redundancy_score, 4)),
            "details": {
                "token_overlap": float(token_overlap),
                "bigram_overlap": float(bigram_overlap),
            },
        }

    def verify(self, draft, outline, history_list, rel_threshold=0.4, red_threshold=0.6):
        """ä¸€é”®éªŒè¯é€»è¾‘"""
        rel = self.calculate_relevancy(draft, outline)
        red = self.calculate_redundancy(draft, history_list)

        is_passed = (rel['score'] >= rel_threshold) and (red['score'] <= red_threshold)

        advice = "Content looks good."
        if rel['score'] < rel_threshold:
            advice = "Content is deviating from the outline. Add more focus on the section mission."
        if red['score'] > red_threshold:
            advice = "Content is redundant with previous sections. Provide new information."

        return {
            "is_passed": is_passed,
            "relevancy_index": rel['score'],
            "redundancy_index": red['score'],
            "feedback": advice,
            "raw_data": {"relevancy": rel['details'], "redundancy": red['details']}
        }


# ============ FastAPI åº”ç”¨ ============

# 1. å®šä¹‰æ•°æ®æ ¼å¼ (Pydantic æ¨¡å‹)
# è¿™æ · FastAPI ä¼šè‡ªåŠ¨å¸®ä½ æ£€æŸ¥æ”¶åˆ°çš„æ•°æ®å¯¹ä¸å¯¹
class VerifyRequest(BaseModel):
    draft: str                  # å½“å‰ç”Ÿæˆçš„è‰ç¨¿
    outline: str                # å¯¹åº”çš„å¤§çº²/ä»»åŠ¡è¦æ±‚
    history: List[str] = []     # ä¹‹å‰å·²ç»ç”Ÿæˆçš„ç« èŠ‚å†…å®¹åˆ—è¡¨ï¼ˆç”¨äºæŸ¥é‡ï¼‰
    document_id: Optional[str] = None  # å¦‚æœä¸ä¼  historyï¼Œå¯ç”¨ document_id ä»æ•°æ®åº“è¯»å–
    rel_threshold: Optional[float] = 0.6  # å¯é€‰ï¼šè‡ªå®šä¹‰ç›¸å…³æ€§é˜ˆå€¼
    red_threshold: Optional[float] = 0.7  # å¯é€‰ï¼šè‡ªå®šä¹‰å†—ä½™åº¦é˜ˆå€¼

# 2. åˆå§‹åŒ–åº”ç”¨
app = FastAPI(title="FlowerNet Verifying Layer API")

# å…¨å±€ verifier å¯¹è±¡ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
_verifier = None
_history_manager = None

def get_verifier():
    """å»¶è¿Ÿåˆå§‹åŒ– verifierï¼ˆé¦–æ¬¡ä½¿ç”¨æ—¶æ‰åˆ›å»ºï¼‰"""
    global _verifier
    if _verifier is None:
        print("â³ é¦–æ¬¡åˆå§‹åŒ– Verifier...")
        _verifier = FlowerNetVerifier()
        print("âœ… Verifier å·²åˆå§‹åŒ–")
    return _verifier

def get_history_manager():
    """å»¶è¿Ÿåˆå§‹åŒ– HistoryManagerï¼ˆç”¨äºä»æ•°æ®åº“è¯»å–å†å²å†…å®¹ï¼‰"""
    global _history_manager
    if _history_manager is None:
        use_db = os.getenv('USE_DATABASE', 'false').lower() == 'true'
        db_path = os.getenv('DATABASE_PATH', 'flowernet_history.db')
        _history_manager = HistoryManager(use_database=use_db, db_path=db_path)
    return _history_manager

print("ğŸš€ FlowerNet API å¯åŠ¨ï¼ˆVerifier å°†æŒ‰éœ€åˆå§‹åŒ–ï¼‰...")

# 3. å®šä¹‰æ ¹ç›®å½•ï¼ˆç”¨äºæ£€æŸ¥æœåŠ¡æ˜¯å¦å­˜æ´»ï¼‰
@app.get("/")
def read_root():
    return {"status": "online", "message": "FlowerNet Verifying Layer is ready."}

# 4. å®šä¹‰æ ¸å¿ƒéªŒè¯æ¥å£
@app.post("/verify")
async def perform_verification(request: VerifyRequest):
    try:
        # è·å–æˆ–åˆ›å»º verifierï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        verifier = get_verifier()
        history_list = request.history
        if (not history_list) and request.document_id:
            history_manager = get_history_manager()
            history_records = history_manager.get_history(request.document_id)
            history_list = [entry["content"] for entry in history_records]
        # è°ƒç”¨ verifier.py ä¸­çš„ verify æ–¹æ³•
        result = verifier.verify(
            draft=request.draft,
            outline=request.outline,
            history_list=history_list,
            rel_threshold=request.rel_threshold,
            red_threshold=request.red_threshold
        )
        return result
    except Exception as e:
        # å¦‚æœä»£ç å‡ºé”™ï¼Œè¿”å› 500 é”™è¯¯
        raise HTTPException(status_code=500, detail=str(e))

# 5. æœ¬åœ°ç›´æ¥è¿è¡Œè„šæœ¬çš„å¿«æ·å…¥å£
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

